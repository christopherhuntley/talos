{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "075dd4a3-3f17-4f62-9955-37fb15e17290",
   "metadata": {},
   "source": [
    "# IRS 990 Data ETL\n",
    "**This notebook includes code needed to populate a data lake with IRS 990 data. Note: it rebuilds the data lake from scratch each time.**\n",
    "\n",
    "## Bulk Downloads from IRS\n",
    "\n",
    "This is a short BASH script to download all 990 xml files to date. \n",
    "- Downloads are incremental, with \"no clobber\" settings used to avoid redundant downloads\n",
    "- The `$CYEAR` variable represents the current year in XXXX format \n",
    "- The `$DEST` variable is a directory path for storing the files\n",
    "- TODO: Allow overrides from environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c33d7-6bf9-433d-9315-7984a9ee440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "CYEAR=`date +\"%Y\"`\n",
    "DEST=./990data/raw/\n",
    "for y in $(seq 2015 $CYEAR); do\n",
    "    PART=1\n",
    "    COMPLETE=0\n",
    "    until [ $COMPLETE -eq 1 ]; do\n",
    "        URL=\"https://apps.irs.gov/pub/epostcard/990/xml/${y}/download990xml_${y}_${PART}.zip\"\n",
    "        wget -q -N $URL -P $DEST\n",
    "        if head $DEST/download990xml_${y}_${PART}.zip | grep -q html; then\n",
    "            COMPLETE=1\n",
    "            rm -f $DEST/download990xml_${y}_${PART}.zip\n",
    "        else\n",
    "            echo \"Updating/Downloading $URL\"\n",
    "        fi\n",
    "        ((PART++))\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b0560-0665-4a2f-8d9b-b64ea70af821",
   "metadata": {},
   "source": [
    "## Data ETL\n",
    "\n",
    "This is Python code to \n",
    "- extract (parse) data from zipped-XML files; the output is a data tree (`tree_data`)\n",
    "- transform the data to suit various potential uses and schema (tabular, hierarchical, etc.) \n",
    "- load (export) the data to destinations by file format and year(csv files, json files, relational DBs)\n",
    "\n",
    "The process is somewhat monolithic:\n",
    "- rebuilds the entire lake from scratch\n",
    "- handles all data formats, one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb043480-c3aa-43c1-a3cf-a4f773132ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990data/raw/download990xml_2015_1.zip 2015\n",
      "0 201502549349100000_public.xml\n",
      "1000 201502599349200115_public.xml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 226>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m         xml_tree \u001b[38;5;241m=\u001b[39m ET\u001b[38;5;241m.\u001b[39mparse(f)\n\u001b[1;32m    247\u001b[0m         xml_root \u001b[38;5;241m=\u001b[39m xml_tree\u001b[38;5;241m.\u001b[39mgetroot()\n\u001b[0;32m--> 249\u001b[0m         data_tree \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mreturn_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# exports\u001b[39;00m\n\u001b[1;32m    252\u001b[0m export_to_csv(data_tree, year,part)\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mreturn_tree\u001b[0;34m(root, fname)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreturn_tree\u001b[39m(root,fname): \n\u001b[0;32m--> 162\u001b[0m     tree \u001b[38;5;241m=\u001b[39m \u001b[43mparse_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     tree[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mofficers\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_officers(root,fname)\n\u001b[1;32m    164\u001b[0m     tree[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrants\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_grants(root,fname)\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mparse_return\u001b[0;34m(root, fname)\u001b[0m\n\u001b[1;32m     70\u001b[0m fields[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbusiness_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m coalesce(\n\u001b[1;32m     71\u001b[0m     safe_text(root\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//Filer/BusinessName/*\u001b[39m\u001b[38;5;124m'\u001b[39m,ns)),\n\u001b[1;32m     72\u001b[0m     safe_text(root\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//Filer/Name/*\u001b[39m\u001b[38;5;124m'\u001b[39m,ns))\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     74\u001b[0m fields[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbusiness_address\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m safe_text(root\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//Filer/USAddress/*\u001b[39m\u001b[38;5;124m'\u001b[39m,ns))\n\u001b[1;32m     75\u001b[0m fields[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreparer_firm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m coalesce(\n\u001b[1;32m     76\u001b[0m     safe_text(root\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//PreparerFirmName/*\u001b[39m\u001b[38;5;124m'\u001b[39m,ns)),\n\u001b[0;32m---> 77\u001b[0m     safe_text(\u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.//PreparerFirmBusinessName/*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mns\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     79\u001b[0m fields[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreparer_address\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m coalesce(\n\u001b[1;32m     80\u001b[0m     safe_text(root\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//PreparerUSAddress/*\u001b[39m\u001b[38;5;124m'\u001b[39m,ns)),\n\u001b[1;32m     81\u001b[0m     safe_text(root\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//PreparerFirmUSAddress/*\u001b[39m\u001b[38;5;124m'\u001b[39m,ns))\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     84\u001b[0m fields[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtax_year\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m coalesce(\n\u001b[1;32m     85\u001b[0m     safe_text(root\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//TaxYr\u001b[39m\u001b[38;5;124m'\u001b[39m,ns)), \n\u001b[1;32m     86\u001b[0m     safe_text(root\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//TaxYear\u001b[39m\u001b[38;5;124m'\u001b[39m,ns))\n\u001b[1;32m     87\u001b[0m )\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/xml/etree/ElementPath.py:389\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(elem, path, namespaces)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind\u001b[39m(elem, path, namespaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/xml/etree/ElementPath.py:173\u001b[0m, in \u001b[0;36mprepare_star.<locals>.select\u001b[0;34m(context, result)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(context, result):\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m elem\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/xml/etree/ElementPath.py:208\u001b[0m, in \u001b[0;36mprepare_descendant.<locals>.select\u001b[0;34m(context, result)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(context, result):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m--> 208\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m elem\u001b[38;5;241m.\u001b[39miter(tag):\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m elem:\n\u001b[1;32m    210\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m e\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# ----------------- Logging ----------------------------------------------\n",
    "\n",
    "# import logging\n",
    "# logger = logging.getLogger()\n",
    "# fhandler = logging.FileHandler(filename='test_log.log', mode='a')\n",
    "# logger.addHandler(fhandler)\n",
    "# logger.setLevel(logging.INFO)\n",
    "# logging.debug(\"test\")\n",
    "\n",
    "import logging\n",
    "import datetime\n",
    "#logging.basicConfig(filename='test_log.log', encoding='utf-8', mode='w', level=logging.DEBUG, force=True, format='%{message}s')\n",
    "logging.basicConfig(filename='test_log.log', level=logging.DEBUG, force=True, format='%(levelname)s:%(message)s')\n",
    "\n",
    "# -------------- Constants / Environment Vars-----------------------------\n",
    "\n",
    "# Namespace for XML parsing\n",
    "ns = {'':'http://www.irs.gov/efile'}\n",
    "\n",
    "# Locations of the data directories\n",
    "data_dir = Path('./990data')\n",
    "raw_zips_dir = data_dir / 'raw'\n",
    "json_dir = data_dir / 'json'\n",
    "csv_dir = data_dir / 'csv'\n",
    "tmp_dir = data_dir / 'tmp'\n",
    "\n",
    "# -------------------- Utilities -----------------------------------------\n",
    "\n",
    "def safe_text(elements):\n",
    "    \n",
    "    '''A text extraction utility for ElementTree(s)''' \n",
    "    \n",
    "    if elements is None:\n",
    "        return ''\n",
    "    elif type(elements) == ET.Element: \n",
    "        # singular\n",
    "        return elements.text\n",
    "    else:\n",
    "        # plural\n",
    "        return ' '.join([e.text for e in elements]) \n",
    "\n",
    "def coalesce(*values):\n",
    "    \n",
    "    \"\"\"Return the first non-None value or None if all values are None\"\"\"\n",
    "    # src: https://gist.githubusercontent.com/onelharrison/37a1d153246a5e1d2336c444f05522a6/raw/3075d414eee9d45a6558513bcd33f4a266b57e77/coalesce.py\n",
    "    \n",
    "    return next((v for v in values if v is not None and v != ''), None)\n",
    "\n",
    "# ----------- XML Parser functions for various parts of the return --------------- \n",
    "        \n",
    "def parse_return(root,fname):\n",
    "    \n",
    "    '''Packages an XML return's header data as a dictionary'''\n",
    "    \n",
    "    fields = {}\n",
    "    \n",
    "    fields['src_fname'] = fname\n",
    "    fields['return_type'] = coalesce(\n",
    "        safe_text(root.find('.//ReturnTypeCd',ns)),\n",
    "        safe_text(root.find('.//ReturnType',ns))\n",
    "    )\n",
    "    fields['ein'] = safe_text(root.find('.//Filer/EIN',ns))\n",
    "    fields['business_name'] = coalesce(\n",
    "        safe_text(root.find('.//Filer/BusinessName/*',ns)),\n",
    "        safe_text(root.find('.//Filer/Name/*',ns))\n",
    "    )\n",
    "    fields['business_address'] = safe_text(root.findall('.//Filer/USAddress/*',ns))\n",
    "    fields['preparer_firm'] = coalesce(\n",
    "        safe_text(root.find('.//PreparerFirmName/*',ns)),\n",
    "        safe_text(root.find('.//PreparerFirmBusinessName/*',ns))\n",
    "    )\n",
    "    fields['preparer_address'] = coalesce(\n",
    "        safe_text(root.findall('.//PreparerUSAddress/*',ns)),\n",
    "        safe_text(root.findall('.//PreparerFirmUSAddress/*',ns))\n",
    "    )\n",
    "    \n",
    "    fields['tax_year']= coalesce(\n",
    "        safe_text(root.find('.//TaxYr',ns)), \n",
    "        safe_text(root.find('.//TaxYear',ns))\n",
    "    )\n",
    "    return fields\n",
    "\n",
    "def parse_officers(root,fname):\n",
    "    \n",
    "    '''Packages data about company officers as a list of dictionaries'''\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    # officers listed in data\n",
    "    officers = root.findall('.//OfficerDirTrstKeyEmplGrp',ns)\n",
    "    officers += root.findall('.//OfficerDirectorTrusteeEmplGrp',ns)\n",
    "    officers += root.findall('.//OfcrDirTrusteesOrKeyEmployee',ns)\n",
    "    officers += root.findall('.//Form990PartVIISectionAGrp',ns)\n",
    "    \n",
    "    for officer in officers:\n",
    "        fields = {\n",
    "            'name': coalesce(\n",
    "                safe_text(officer.find('PersonNm',ns)),\n",
    "                safe_text(officer.findall('.//BusinessName/*',ns)),\n",
    "                safe_text(officer.find('PersonName',ns))\n",
    "            ),\n",
    "            'title': coalesce(\n",
    "                safe_text(officer.find('TitleTxt',ns)),\n",
    "                safe_text(officer.find('Title',ns))\n",
    "            ),\n",
    "            'address': safe_text(officer.findall('.//USAddress/*',ns))\n",
    "        }\n",
    "        records += [fields]\n",
    "    \n",
    "    # officer listed in header; only use if no other records found\n",
    "    if not records:\n",
    "        officer = root.find('.//BusinessOfficerGrp',ns)\n",
    "        \n",
    "        if officer == None:\n",
    "            officer = root.find('.//Officer',ns)\n",
    "            \n",
    "        fields = {\n",
    "            'name': coalesce(\n",
    "                safe_text(officer.find('PersonNm',ns)),\n",
    "                safe_text(officer.find('Name',ns))\n",
    "            ),\n",
    "            'title': coalesce(\n",
    "                safe_text(officer.find('PersonTitleTxt',ns)),\n",
    "                safe_text(officer.find('Title',ns))\n",
    "            ),\n",
    "            'address': ''\n",
    "        }\n",
    "        records += [fields]\n",
    "    \n",
    "    return records\n",
    "\n",
    "def parse_grants(root,fname):\n",
    "    \n",
    "    '''Packages data about grants and contributions as a list of dictionaries'''\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    grants = root.findall('.//GrantOrContributionPdDurYrGrp',ns)\n",
    "    for grant in grants:\n",
    "        fields = {\n",
    "            'recipient_name': coalesce(\n",
    "                safe_text(grant.find('RecipientPersonNm',ns)), \n",
    "                safe_text(grant.findall('.//RecipientBusinessName/*',ns))\n",
    "            ),\n",
    "            'recipient_address': safe_text(grant.findall('.//RecipientUSAddress/*',ns)),\n",
    "            'purpose': safe_text(grant.find('.//GrantOrContributionPurposeTxt',ns)),\n",
    "            'amount': safe_text(grant.find('Amt',ns))\n",
    "        }\n",
    "        records += [fields]\n",
    "        \n",
    "    return records\n",
    "\n",
    "\n",
    "def return_tree(root,fname): \n",
    "    tree = parse_return(root,fname)\n",
    "    tree['officers'] = parse_officers(root,fname)\n",
    "    tree['grants'] = parse_grants(root,fname)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "# ----------- EXPORT Functions for various formats ---------------------\n",
    "\n",
    "def export_to_csv(data_tree,year,part,zipmode=\"w\"):\n",
    "    \n",
    "    '''Exports a data tree to keyed csv files'''\n",
    "    \n",
    "    returns = list(data_tree)\n",
    "    officers = []\n",
    "    grants = []\n",
    "    for r in returns:\n",
    "        for o in r['officers']:\n",
    "            o['src_fname'] = r['src_fname'] \n",
    "            officers += [o]\n",
    "        \n",
    "        for g in r['grants']:\n",
    "            g['src_fname'] = r['src_fname'] \n",
    "            grants += [g]\n",
    "            \n",
    "    # generate returns.csv\n",
    "    df = pd.DataFrame(returns)\n",
    "    del df['officers']\n",
    "    del df['grants']\n",
    "    df.to_csv(\"tmp/returns.csv\",mode=\"w\",index=False)\n",
    "    \n",
    "    # generate officers.csv\n",
    "    df = pd.DataFrame(officers)\n",
    "    df.to_csv(\"tmp/officers.csv\",mode=\"w\",index=False)\n",
    "    \n",
    "    # generate grants.csv\n",
    "    df = pd.DataFrame(grants)\n",
    "    df.to_csv(\"tmp/grants.csv\",mode=\"w\",index=False)\n",
    "    \n",
    "    # export to zipfile\n",
    "    fname = \"IRS990_csv_\" + str(year)+ \"_part_\"+ str(part) + \".zip\"\n",
    "    with zipfile.ZipFile(csv_dir / fname, mode=zipmode, compression = zipfile.ZIP_DEFLATED) as outzip:\n",
    "        prefix = \"IRS990_csv_\" + str(year)+ \"_part_\"+ str(part)+\"_\"\n",
    "        outzip.write(\"tmp/returns.csv\",prefix+\"returns.csv\")\n",
    "        outzip.write(\"tmp/officers.csv\",prefix+\"officers.csv\")\n",
    "        outzip.write(\"tmp/grants.csv\",prefix+\"grants.csv\")\n",
    "    \n",
    "\n",
    "def export_to_json(data_tree,year,part, zipmode=\"w\"):\n",
    "    \n",
    "    '''Exports a data tree as a json file'''\n",
    "    \n",
    "    with open(\"tmp/returns.json\",'w') as jf:\n",
    "        json.dump(data_tree,jf)\n",
    "    \n",
    "    fname = \"IRS990_json_\" + str(year)+ \"_part_\"+ str(part) + \".zip\"\n",
    "    with zipfile.ZipFile(json_dir / fname, mode=zipmode, compression = zipfile.ZIP_DEFLATED) as outzip:\n",
    "        prefix = \"IRS990_json_\" + str(year)+ \"_part_\"+ str(part)+\"_\"\n",
    "        outzip.write(\"tmp/returns.json\", prefix + \"returns.json\")\n",
    "   \n",
    "\n",
    "# -------------------- Main code --------------------------------\n",
    "# process each zipped xml file in the raw downloads directory\n",
    "now = datetime.datetime.now()\n",
    "logging.info(f\"Run started {now}\")\n",
    "for zf_path in sorted(list(raw_zips_dir.glob('./*.zip'))):\n",
    "    \n",
    "    # extract the year from the zf_path\n",
    "    year = zf_path.name.split(\"_\")[1]\n",
    "    part = zf_path.name.split(\"_\")[2].split(\".\")[0]\n",
    "    \n",
    "    print(f\"{zf_path} {year}\")\n",
    "    logging.info(f\"{zf_path} {year}\")\n",
    "    \n",
    "    zf = zipfile.ZipFile(zf_path, 'r')\n",
    "    \n",
    "    # processes each xml document in the zip; builds up a data tree\n",
    "    data_tree = []\n",
    "    for i,fname in enumerate(zf.namelist()):\n",
    "        if (i % 1000 == 0):\n",
    "            print(f\"{i} {fname}\")\n",
    "            logging.info(f\"{i} {fname}\")\n",
    "        \n",
    "        # extract the xml into a live ET tree\n",
    "        with zf.open(fname) as f:\n",
    "            xml_tree = ET.parse(f)\n",
    "            xml_root = xml_tree.getroot()\n",
    "\n",
    "            data_tree += [return_tree(xml_root,fname)]\n",
    "    \n",
    "    # exports\n",
    "    export_to_csv(data_tree, year,part)\n",
    "    export_to_json(data_tree, year,part)\n",
    "      \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecdb1f6-e5a2-449f-b723-689e91f02c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aedda68-12c0-4539-a272-d7cc548e29b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
